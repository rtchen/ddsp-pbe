# -*-Python-*-
# ABS (Analysis by Synthesis). Jointly learns an encoder for f0.
# z, f0 = encoder(audio)

include 'models/ae.gin'

# Encoder (with F0 encoder)
MfccTimeDistributedRnnEncoder.z_time_steps = 250
MfccTimeDistributedRnnEncoder.f0_encoder = @encoders.ResnetF0Encoder()
ResnetF0Encoder.size = 'small'
ResnetF0Encoder.f0_bins = 256

# FFT input parameters from onsets and frames transcription experiments.
ResnetF0Encoder.spectral_fn = @f0_spectral/spectral_ops.compute_logmel
f0_spectral/compute_logmel.lo_hz = 0.0
f0_spectral/compute_logmel.hi_hz = 8000.0
f0_spectral/compute_logmel.bins = 229
f0_spectral/compute_logmel.fft_size = 2048
f0_spectral/compute_logmel.overlap = 0.75
f0_spectral/compute_logmel.pad_end = True

# Add perceptual loss
Autoencoder.losses = [
    @losses.SpectralLoss(),
    @losses.PretrainedCREPEEmbeddingLoss(),
]

# Crepe
PretrainedCREPEEmbeddingLoss.name = 'crepe'
PretrainedCREPEEmbeddingLoss.loss_type = 'L1'
PretrainedCREPEEmbeddingLoss.weight = 0.1
PretrainedCREPEEmbeddingLoss.activation_layer = 'conv5-maxpool'
PretrainedCREPEEmbeddingLoss.model_capacity = 'tiny'
